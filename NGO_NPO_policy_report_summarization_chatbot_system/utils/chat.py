import os
import json
from dotenv import load_dotenv
from .database import db
from .request_rag import call_rag_api
import requests
from typing import Dict, List, Optional, Union, Generator

load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
API_KEY = os.getenv("UPSTAGE_API_KEY")
API_URL = "https://api.upstage.ai/v1/chat/completions"

def chat_with_upstage(messages, model="solar-pro2-preview", stream=False, reasoning_effort="medium"):
    """
    Upstage APIë¥¼ ì‚¬ìš©í•œ ì±„íŒ… í•¨ìˆ˜
    
    Args:
        messages: ì±„íŒ… ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ [{"role": "user", "content": "..."}]
        model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: solar-pro2-preview)
        stream: ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        reasoning_effort: ì¶”ë¡  ê°•ë„ ("low", "medium", "high")
    
    Returns:
        ì‘ë‹µ í…ìŠ¤íŠ¸ ë˜ëŠ” ìŠ¤íŠ¸ë¦¼ ê°ì²´
    """
    try:
        response = requests.post(
            API_URL,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": model,
                "messages": messages,
                "reasoning_effort": reasoning_effort,
                "stream": stream
            }
        )
        
        if response.status_code == 200:
            if stream:
                return response
            else:
                return response.json()["choices"][0]["message"]["content"]
        else:
            print(f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code} - {response.text}")
            return None
            
    except Exception as e:
        print(f"ì±„íŒ… API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None



def summarize_conversation_history(chat_history):
    """
    ëŒ€í™” ê¸°ë¡ì„ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜ (í˜„ì¬ ì„¸ì…˜ë§Œ)
    
    Args:
        chat_history: ìš”ì•½í•  ëŒ€í™” ê¸°ë¡ ë¦¬ìŠ¤íŠ¸ (í˜„ì¬ ì„¸ì…˜ë§Œ)
    
    Returns:
        ìš”ì•½ëœ ëŒ€í™” ë‚´ìš©
    """
    if not chat_history:
        return ""
    
    # ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    conversation_text = ""
    for msg in chat_history:
        if msg["role"] in ["user", "assistant"]:
            role_name = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI"
            content = msg["content"]
            # íŠ¹ìˆ˜ í˜•ì‹ ë©”ì‹œì§€ ì œì™¸
            if not content.startswith("ğŸ“„") and not content.startswith("âŒ"):
                conversation_text += f"{role_name}: {content}\n\n"
    
    if not conversation_text.strip():
        return ""
    
    # ìš”ì•½ ìƒì„±
    messages = [
        {
            "role": "system",
            "content": """ë‹¹ì‹ ì€ ëŒ€í™” ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ëŒ€í™” ë‚´ìš©ì„ ê°„ê²°í•˜ê³  í•µì‹¬ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
ìš”ì•½ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

**í˜„ì¬ ì„¸ì…˜ ëŒ€í™” ìš”ì•½:**
- ì£¼ìš” ì§ˆë¬¸ê³¼ ë‹µë³€ ë‚´ìš©ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ì •ë¦¬
- ì¤‘ìš”í•œ ë§¥ë½ì´ë‚˜ ì •ë³´ë¥¼ í¬í•¨
- 3-5ê°œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±

ëŒ€í™”ì˜ íë¦„ê³¼ í•µì‹¬ ë‚´ìš©ì„ ìœ ì§€í•˜ë©´ì„œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
ì´ ìš”ì•½ì€ í˜„ì¬ ì„¸ì…˜ì˜ ë§¥ë½ ìœ ì§€ë¥¼ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤."""
        },
        {
            "role": "user",
            "content": f"ë‹¤ìŒ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{conversation_text}"
        }
    ]
    
    try:
        summary = chat_with_upstage(messages, reasoning_effort="medium")
        return summary if summary else ""
    except:
        return ""





def summarize_document(text, language="Korean"):
    """
    ë¬¸ì„œ ìš”ì•½ í•¨ìˆ˜
    
    Args:
        text: ìš”ì•½í•  í…ìŠ¤íŠ¸
        language: ìš”ì•½ ì–¸ì–´ (ê¸°ë³¸ê°’: Korean)
    
    Returns:
        ìš”ì•½ëœ í…ìŠ¤íŠ¸
    """
    system_content = f"""ë‹¹ì‹ ì€ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ {language}ë¡œ ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‚´ìš©ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
ìš”ì•½ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ì£¼ìš” ë‚´ìš©
- í•µì‹¬ í¬ì¸íŠ¸ë“¤ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ì •ë¦¬

## ê²°ë¡ 
- ë¬¸ì„œì˜ ì£¼ìš” ê²°ë¡ ì´ë‚˜ ì‹œì‚¬ì 

ìš”ì•½ì€ ì›ë¬¸ì˜ 20% ì´ë‚´ ê¸¸ì´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
    
    messages = [
        {
            "role": "system",
            "content": system_content
        },
        {
            "role": "user", 
            "content": f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{text}"
        }
    ]
    
    return chat_with_upstage(messages, reasoning_effort="high")

def search_rag_documents(query):
    """RAG ì‹œìŠ¤í…œì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        rag_response = call_rag_api(query)
        if rag_response and "results" in rag_response and rag_response["results"]:
            return rag_response["results"]
        return []
    except Exception as e:
        print(f"RAG ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def get_rag_tools():
    """RAG ê²€ìƒ‰ì„ ìœ„í•œ ë„êµ¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return [
        {
            "type": "function",
            "function": {
                "name": "search_documents",
                "description": "ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ìŠµë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "ê²€ìƒ‰í•  ì¿¼ë¦¬"
                        }
                    },
                    "required": ["query"]
                }
            }
        }
    ]

def process_rag_response(tool_calls):
    """RAG ì‘ë‹µì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        reference_info = ""
        rag_results = []
        
        if tool_calls:
            for tool_call in tool_calls:
                if tool_call.function.name == "search_documents":
                    results = json.loads(tool_call.function.arguments)
                    rag_results = results.get("results", [])
                    
                    if rag_results:
                        reference_info = "### ğŸ“š ì°¸ê³  ë¬¸ì„œ\n\n"
                        for i, result in enumerate(rag_results[:3], 1):
                            reference_info += f"**{i}. {result.get('filename', 'N/A')}**\n"
                            reference_info += f"{result.get('content', 'ë‚´ìš© ì—†ìŒ')}\n\n"
        
        return reference_info, rag_results
    except Exception as e:
        print(f"Error in process_rag_response: {str(e)}")
        return "", []

def should_use_rag(user_input: str, pdf_summary: str = None, conversation_history: List[Dict] = None) -> bool:
    """
    RAG ì‚¬ìš© ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥
        pdf_summary: PDF ìš”ì•½ (ì„ íƒ)
        conversation_history: ëŒ€í™” ê¸°ë¡ (ì„ íƒ)
    
    Returns:
        bool: RAG ì‚¬ìš© ì—¬ë¶€
    """
    try:
        # RAG í•„ìš”ì„± íŒë‹¨ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        rag_decision_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ RAG(Retrieval Augmented Generation)ê°€ í•„ìš”í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {user_input}

{f'PDF ìš”ì•½: {pdf_summary}' if pdf_summary else ''}

RAGê°€ í•„ìš”í•œ ê²½ìš°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
1. ì§ˆë¬¸ì´ êµ¬ì²´ì ì¸ ì •ë³´ë‚˜ ì‚¬ì‹¤ì„ ìš”êµ¬í•˜ëŠ” ê²½ìš°
2. ì§ˆë¬¸ì´ íŠ¹ì • ë¬¸ì„œë‚˜ ìë£Œì˜ ë‚´ìš©ì„ ì°¸ì¡°í•´ì•¼ í•˜ëŠ” ê²½ìš°
3. ì§ˆë¬¸ì´ ì „ë¬¸ì ì¸ ì§€ì‹ì´ë‚˜ êµ¬ì²´ì ì¸ ë°ì´í„°ê°€ í•„ìš”í•œ ê²½ìš°
4. ì§ˆë¬¸ì´ ê²€ìƒ‰ì´ë‚˜ ì°¾ê¸°ì™€ ê´€ë ¨ëœ ê²½ìš°

RAGê°€ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
1. ì¼ë°˜ì ì¸ ëŒ€í™”ë‚˜ ì¸ì‚¬ì¸ ê²½ìš°
2. ì¶”ìƒì ì¸ ì§ˆë¬¸ì´ë‚˜ ì˜ê²¬ì„ ë¬»ëŠ” ê²½ìš°
3. ê°„ë‹¨í•œ ì„¤ëª…ì´ë‚˜ ì •ì˜ë¥¼ ìš”êµ¬í•˜ëŠ” ê²½ìš°
4. ëŒ€í™”ì˜ ë§¥ë½ë§Œìœ¼ë¡œ ì¶©ë¶„íˆ ë‹µë³€ ê°€ëŠ¥í•œ ê²½ìš°

RAGê°€ í•„ìš”í•œì§€ ì—¬ë¶€ë¥¼ 'yes' ë˜ëŠ” 'no'ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        # LLMì„ ì‚¬ìš©í•˜ì—¬ RAG í•„ìš”ì„± íŒë‹¨
        response = requests.post(
            API_URL,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "solar-1-mini-chat",
                "messages": [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ RAG í•„ìš”ì„±ì„ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": rag_decision_prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 10
            }
        )
        
        decision = response.json()["choices"][0]["message"]["content"].lower().strip()
        return decision == 'yes'
        
    except Exception as e:
        print(f"RAG í•„ìš”ì„± íŒë‹¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def get_chat_response(
    messages: List[Dict],
    system_prompt: str,
    user_input: str,
    use_rag: bool = False,
    pdf_summary: str = None
) -> Dict:
    """
    ì±„íŒ… ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        messages: ëŒ€í™” ê¸°ë¡
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        user_input: ì‚¬ìš©ì ì…ë ¥
        use_rag: RAG ì‚¬ìš© ì—¬ë¶€
        pdf_summary: PDF ìš”ì•½
    
    Returns:
        Dict: ì‘ë‹µ ì •ë³´
    """
    try:
        # RAG í•„ìš”ì„± íŒë‹¨
        should_use_rag_flag = should_use_rag(user_input, pdf_summary, messages) if use_rag else False
        
        if should_use_rag_flag:
            # PDF ìš”ì•½ì´ ìˆëŠ” ê²½ìš° ê²€ìƒ‰ ì¿¼ë¦¬ì— í¬í•¨
            search_query = user_input
            if pdf_summary:
                search_query = f"PDF ë‚´ìš©: {pdf_summary}\n\nì§ˆë¬¸: {user_input}"
            
            # RAG API í˜¸ì¶œ
            rag_response = call_rag_api(search_query)
            
            if rag_response and "results" in rag_response and rag_response["results"]:
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ìš© ì°¸ê³  ìë£Œ (ì›ë³¸)
                system_reference = '### ğŸ“š ì°¸ê³  ì‚¬ë¡€\n\n'
                system_reference += 'ì•„ë˜ëŠ” ì°¸ê³ ìš© ì‚¬ë¡€ì…ë‹ˆë‹¤. ì´ ì‚¬ë¡€ë“¤ì€ ë‹µë³€ì˜ ì°¸ê³  ìë£Œë¡œë§Œ ì‚¬ìš©ë˜ë©°, ì§ì ‘ì ì¸ ë‹µë³€ì€ ì•„ë‹™ë‹ˆë‹¤.\n\n'
                
                # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì°¸ê³  ìë£Œ (ìš”ì•½)
                display_reference = '### ğŸ“š ì°¸ê³  ì‚¬ë¡€\n\n'
                
                for i, result in enumerate(rag_response["results"][:3], 1):
                    content = result.get("content", "ë‚´ìš© ì—†ìŒ")
                    filename = result.get("filename", "N/A")
                    similarity = result.get("similarity", 0)
                    
                    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ìš© ì›ë³¸ ë‚´ìš©
                    system_reference += f'**ì‚¬ë¡€ {i}**\n'
                    system_reference += f'**íŒŒì¼ëª…**: {filename}\n\n'
                    system_reference += f'**ë‚´ìš©**:\n{content}\n\n'
                    system_reference += f'**ìœ ì‚¬ë„**: {similarity:.3f}\n\n'
                    system_reference += '---\n\n'
                    
                    # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìš”ì•½ ë‚´ìš©
                    summarized_content = summarize_content(content)
                    display_reference += f'**ì‚¬ë¡€ {i}**\n'
                    display_reference += f'**íŒŒì¼ëª…**: {filename}\n\n'
                    display_reference += f'**ë‚´ìš©**:\n{summarized_content}\n\n'
                    display_reference += f'**ìœ ì‚¬ë„**: {similarity:.3f}\n\n'
                    display_reference += '---\n\n'
                
                system_prompt = f"""{system_prompt}

ì•„ë˜ì˜ ì°¸ê³  ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì´ ì‚¬ë¡€ë“¤ì€ ì°¸ê³ ìš©ì´ë©°, ì§ˆë¬¸ê³¼ëŠ” ê´€ë ¨ì´ ì—†ìŠµë‹ˆë‹¤. 
ë¬¸ì„œë¥¼ ë¶„ì„í•  ë•Œ ì•„ë˜ì˜ ì‚¬ë¡€ë¥¼ ì ì ˆíˆ ì¸ìš©í•˜ì—¬ ë‹µë³€í•˜ì‹­ì‹œì˜¤.

{system_reference}"""
            else:
                system_reference = "ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                display_reference = system_reference
        else:
            system_reference = ""
            display_reference = ""
            
        if pdf_summary:
            system_prompt += f"""ì•„ë˜ì˜ ì‚¬ë¡€ëŠ” ìœ ì €ê°€ ì§ì ‘ì ìœ¼ë¡œ ì…ë ¥í•œ pdfì˜ ìš”ì•½ì…ë‹ˆë‹¤. ìœ„ ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ë¬¸ì„œì— ëŒ€í•œ ìœ ì €ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
            \n\n
{pdf_summary}"""

        response = requests.post(
            API_URL,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "solar-1-mini-chat",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    *messages,
                    {"role": "user", "content": user_input}
                ],
                "temperature": 0.7,
                "max_tokens": 1000
            }
        )
        
        if response.status_code == 200:
            response_data = response.json()
            if 'choices' in response_data and len(response_data['choices']) > 0:
                content = response_data['choices'][0]['message']['content']
                # ì°¸ê³  ìë£Œê°€ ìˆëŠ” ê²½ìš° ë§ˆì§€ë§‰ì— ì¶”ê°€ (ìš”ì•½ëœ ë²„ì „)
                if should_use_rag_flag and display_reference:
                    content += f"\n\n{display_reference}"
                return {
                    "response": content,
                    "reference": display_reference if should_use_rag_flag else ""
                }
        
        return {
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "reference": ""
        }
        
    except Exception as e:
        print(f"Error in get_chat_response: {str(e)}")
        return {
            "response": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "reference": ""
        }

def summarize_content(content: str) -> str:
    try:
        response = requests.post(
            API_URL,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "solar-1-mini-chat",
                "messages": [
                    {"role": "system", "content": "ì£¼ì–´ì§„ ë‚´ìš©ì„ 1-2ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": content}
                ],
                "temperature": 0.7,
                "max_tokens": 500
            }
        )
        
        if response.status_code == 200:
            response_data = response.json()
            if 'choices' in response_data and len(response_data['choices']) > 0:
                return response_data['choices'][0]['message']['content']
        return content[:100] + "..."
    except Exception as e:
        print(f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return content[:100] + "..."

def stream_chat_response_with_memory(
    messages: List[Dict],
    system_prompt: str,
    user_input: str,
    use_rag: bool = False,
    pdf_summary: str = None
) -> Generator[str, None, None]:
    try:
        # RAG í•„ìš”ì„± íŒë‹¨
        should_use_rag_flag = should_use_rag(user_input, pdf_summary, messages) if use_rag else False
        
        if should_use_rag_flag:
            # PDF ìš”ì•½ì´ ìˆëŠ” ê²½ìš° ê²€ìƒ‰ ì¿¼ë¦¬ì— í¬í•¨
            search_query = user_input
            if pdf_summary:
                search_query = f"PDF ë‚´ìš©: {pdf_summary}\n\nì§ˆë¬¸: {user_input}"
            
            # RAG API í˜¸ì¶œ
            rag_response = call_rag_api(search_query)
            
            if rag_response and "results" in rag_response and rag_response["results"]:
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ìš© ì°¸ê³  ìë£Œ (ì›ë³¸)
                system_reference = '### ğŸ“š ì°¸ê³  ì‚¬ë¡€\n\n'
                system_reference += 'ì•„ë˜ëŠ” ì°¸ê³ ìš© ì‚¬ë¡€ì…ë‹ˆë‹¤. ì´ ì‚¬ë¡€ë“¤ì€ ë‹µë³€ì˜ ì°¸ê³  ìë£Œë¡œë§Œ ì‚¬ìš©ë˜ë©°, ì§ì ‘ì ì¸ ë‹µë³€ì€ ì•„ë‹™ë‹ˆë‹¤.\n\n'
                
                # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì°¸ê³  ìë£Œ (ìš”ì•½)
                display_reference = '### ğŸ“š ì°¸ê³  ì‚¬ë¡€\n\n'
                
                for i, result in enumerate(rag_response["results"][:3], 1):
                    content = result.get("content", "ë‚´ìš© ì—†ìŒ")
                    filename = result.get("filename", "N/A")
                    similarity = result.get("similarity", 0)
                    
                    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ìš© ì›ë³¸ ë‚´ìš©
                    system_reference += f'**ì‚¬ë¡€ {i}**\n'
                    system_reference += f'**íŒŒì¼ëª…**: {filename}\n\n'
                    system_reference += f'**ë‚´ìš©**:\n{content}\n\n'
                    system_reference += f'**ìœ ì‚¬ë„**: {similarity:.3f}\n\n'
                    system_reference += '---\n\n'
                    
                    # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìš”ì•½ ë‚´ìš©
                    summarized_content = summarize_content(content)
                    display_reference += f'**ì‚¬ë¡€ {i}**\n'
                    display_reference += f'**íŒŒì¼ëª…**: {filename}\n\n'
                    display_reference += f'**ë‚´ìš©**:\n{summarized_content}\n\n'
                    display_reference += f'**ìœ ì‚¬ë„**: {similarity:.3f}\n\n'
                    display_reference += '---\n\n'
                
                system_prompt = f"""{system_prompt}

ì•„ë˜ì˜ ì°¸ê³  ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì´ ì‚¬ë¡€ë“¤ì€ ì°¸ê³ ìš©ì´ë©°, ì§ˆë¬¸ê³¼ëŠ” ê´€ë ¨ì´ ì—†ìŠµë‹ˆë‹¤. 
ë¬¸ì„œë¥¼ ë¶„ì„í•  ë•Œ ì•„ë˜ì˜ ì‚¬ë¡€ë¥¼ ì ì ˆíˆ ì¸ìš©í•˜ì—¬ ë‹µë³€í•˜ì‹­ì‹œì˜¤.

{system_reference}"""
            else:
                system_reference = "ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                display_reference = system_reference
        else:
            system_reference = ""
            display_reference = ""
            
        if pdf_summary:
            system_prompt += f"""ì•„ë˜ì˜ ì‚¬ë¡€ëŠ” ìœ ì €ê°€ ì§ì ‘ì ìœ¼ë¡œ ì…ë ¥í•œ pdfì˜ ìš”ì•½ì…ë‹ˆë‹¤. ìœ„ ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ë¬¸ì„œì— ëŒ€í•œ ìœ ì €ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
            \n\n
{pdf_summary}"""

        # Upstage API í˜¸ì¶œ
        response = requests.post(
            API_URL,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "solar-1-mini-chat",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    *messages,
                    {"role": "user", "content": user_input}
                ],
                "temperature": 0.7,
                "max_tokens": 1000,
                "stream": True
            },
            stream=True
        )
        
        if response.status_code == 200:
            for line in response.iter_lines():
                if line:
                    try:
                        line = line.decode('utf-8')
                        if line.startswith('data: '):
                            data = line[6:]  # 'data: ' ì œê±°
                            if data == '[DONE]':
                                break
                            try:
                                chunk = json.loads(data)
                                if 'choices' in chunk and len(chunk['choices']) > 0:
                                    delta = chunk['choices'][0].get('delta', {})
                                    if 'content' in delta:
                                        yield delta['content']
                            except json.JSONDecodeError as e:
                                print(f"JSON ë””ì½”ë”© ì˜¤ë¥˜: {e}")
                                continue
                    except UnicodeDecodeError as e:
                        print(f"ìœ ë‹ˆì½”ë“œ ë””ì½”ë”© ì˜¤ë¥˜: {e}")
                        continue
            
            # ì°¸ê³  ìë£Œê°€ ìˆëŠ” ê²½ìš° ë§ˆì§€ë§‰ì— ì¶”ê°€ (ìš”ì•½ëœ ë²„ì „)
            if should_use_rag_flag and display_reference:
                yield f"\n\n{display_reference}"
        else:
            print(f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code} - {response.text}")
            yield "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            
    except Exception as e:
        print(f"Error in stream_chat_response_with_memory: {str(e)}")
        yield f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def summarize_document(content):
    """ë¬¸ì„œë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
    try:
        response = requests.post(
            API_URL,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "solar-pro2-preview",
                "messages": [
                    {"role": "system", "content": "ë¬¸ì„œì˜ ë‚´ìš©ì„ ê°„ë‹¨íˆ í•œêµ­ì–´ë¡œë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": content}
                ]
            }
        )
        return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"ë¬¸ì„œ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def document_based_qa_with_memory(document_content, user_input, messages, system_prompt, use_rag=False):
    """ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        reference_info = ""
        
        # RAG ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°
        if use_rag:
            # ë¨¼ì € agentì—ê²Œ RAG ê²€ìƒ‰ì´ í•„ìš”í•œì§€ ë¬¼ì–´ë´„
            agent_response = requests.post(
                API_URL,
                headers={
                    "Authorization": f"Bearer {API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "solar-pro2-preview",
                    "messages": [
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œì§€ íŒë‹¨í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 'yes' ë˜ëŠ” 'no'ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì¶”ê°€ ì •ë³´ë‚˜ ì°¸ê³  ìë£Œê°€ í•„ìš”í• ê¹Œìš”?\n\në¬¸ì„œ: {document_content}\n\nì§ˆë¬¸: {user_input}"}
                    ]
                }
            )
            
            needs_rag = agent_response.json()["choices"][0]["message"]["content"].lower().strip() == "yes"
            
            if needs_rag:
                # RAG ê²€ìƒ‰ ì‹¤í–‰
                response = requests.post(
                    API_URL,
                    headers={
                        "Authorization": f"Bearer {API_KEY}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "solar-pro2-preview",
                        "messages": [{"role": "user", "content": user_input}],
                        "tools": get_rag_tools(),
                        "tool_choice": "auto"
                    }
                )
                
                response_message = response.json()["choices"][0]["message"]
                tool_calls = response_message.get("tool_calls", [])
                
                reference_info, _ = process_rag_response(tool_calls)
                
                # RAG ê²°ê³¼ë¥¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
                if reference_info:
                    system_prompt += f"\n\nì°¸ê³  ìë£Œ:\n{reference_info}"
        
        # ë¬¸ì„œ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        response = requests.post(
            API_URL,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "solar-pro2-preview",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    *messages,
                    {"role": "user", "content": f"ë¬¸ì„œ ë‚´ìš©:\n{document_content}\n\nì§ˆë¬¸: {user_input}"}
                ]
            }
        )
        
        return {
            "content": response.json()["choices"][0]["message"]["content"],
            "reference_info": reference_info if use_rag else ""
        }
    except Exception as e:
        return {
            "content": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "reference_info": ""
        }

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
def build_conversation_messages(chat_history, system_prompt, current_input, recent_count=7):
    """
    ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•œ ë©”ì‹œì§€ êµ¬ì„± (í”„ë¡œí•„ ê¸°ëŠ¥ ì—†ìŒ)
    
    Args:
        chat_history: í˜„ì¬ ì„¸ì…˜ì˜ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬
        system_prompt: ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        current_input: í˜„ì¬ ì‚¬ìš©ì ì…ë ¥
        recent_count: ê·¸ëŒ€ë¡œ ìœ ì§€í•  ìµœê·¼ ëŒ€í™” ìˆ˜ (ê¸°ë³¸ê°’: 7)
    
    Returns:
        OpenAI í˜•ì‹ì˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    messages = [{"role": "system", "content": system_prompt}]
    
    # í˜„ì¬ ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ì´ recent_count*2 ê°œë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš°
    if len(chat_history) > recent_count * 2:
        # ì´ì „ ëŒ€í™”ë“¤ (ìš”ì•½ ëŒ€ìƒ) - í˜„ì¬ ì„¸ì…˜ë§Œ
        old_history = chat_history[:-recent_count*2]
        # ìµœê·¼ ëŒ€í™”ë“¤ (ê·¸ëŒ€ë¡œ ìœ ì§€) - í˜„ì¬ ì„¸ì…˜ë§Œ
        recent_history = chat_history[-recent_count*2:]
        
        # í˜„ì¬ ì„¸ì…˜ì˜ ì´ì „ ëŒ€í™” ìš”ì•½ ìƒì„±
        conversation_summary = summarize_conversation_history(old_history)
        
        # ìš”ì•½ì´ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— ì¶”ê°€
        if conversation_summary:
            enhanced_system_prompt = f"""{system_prompt}

{conversation_summary}

ìœ„ëŠ” í˜„ì¬ ì„¸ì…˜ì˜ ì´ì „ ëŒ€í™” ìš”ì•½ì…ë‹ˆë‹¤. ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
            messages[0]["content"] = enhanced_system_prompt
        
        # ìµœê·¼ ëŒ€í™”ë§Œ ë©”ì‹œì§€ì— ì¶”ê°€
        target_history = recent_history
    else:
        # ëŒ€í™”ê°€ ì ìœ¼ë©´ í˜„ì¬ ì„¸ì…˜ì˜ ëª¨ë“  ëŒ€í™” ìœ ì§€
        target_history = chat_history
    
    # í˜„ì¬ ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ì„ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    for msg in target_history:
        if msg["role"] in ["user", "assistant"]:
            content = msg["content"]
            # íŠ¹ìˆ˜ í˜•ì‹ ë©”ì‹œì§€ ì œì™¸
            if not content.startswith("ğŸ“„") and not content.startswith("âŒ"):
                messages.append({
                    "role": msg["role"],
                    "content": content
                })
    
    # í˜„ì¬ ì…ë ¥ ì¶”ê°€
    messages.append({"role": "user", "content": current_input})
    
    return messages

def answer_question(question, context=None):
    """
    ì§ˆë¬¸ ë‹µë³€ í•¨ìˆ˜ (ë©”ëª¨ë¦¬ ì—†ìŒ - í•˜ìœ„ í˜¸í™˜ì„±)
    """
    return answer_question_with_memory(question, [], context)

def document_based_qa(document_summary, user_question):
    """
    ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€ í•¨ìˆ˜ (ë©”ëª¨ë¦¬ ì—†ìŒ - í•˜ìœ„ í˜¸í™˜ì„±)
    """
    return document_based_qa_with_memory(document_summary, user_question, [], "")

def stream_chat_response(messages):
    """
    ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì‘ë‹µ í•¨ìˆ˜ (ë©”ëª¨ë¦¬ ì—†ìŒ - í•˜ìœ„ í˜¸í™˜ì„±)
    """
    try:
        stream = chat_with_upstage(messages, stream=True, reasoning_effort="medium")
        
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                yield chunk.choices[0].delta.content
                
    except Exception as e:
        yield f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

def summarize_text(text, max_length=100):
    """í…ìŠ¤íŠ¸ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•©ë‹ˆë‹¤."""
    try:
        response = requests.post(
            API_URL,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "solar-pro2-preview",
                "messages": [
                    {"role": "system", "content": f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {max_length}ì ì´ë‚´ë¡œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ ë‚´ìš©ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": text}
                ]
            }
        )
        return response.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"Error in summarize_text: {str(e)}")
        return text[:max_length] + "..."

def get_llm_response(system_prompt, user_input):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        response = requests.post(
            API_URL,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "solar-pro2-preview",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ]
            }
        )
        return response.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"Error in get_llm_response: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def stream_llm_response(system_prompt, user_input):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        response = requests.post(
            API_URL,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "solar-pro2-preview",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                "stream": True
            }
        )
        
        for chunk in response:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
    except Exception as e:
        print(f"Error in stream_llm_response: {str(e)}")
        yield "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤." 